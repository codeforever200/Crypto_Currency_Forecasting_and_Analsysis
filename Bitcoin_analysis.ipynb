{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeforever200/Crypto_Currency_Forecasting_and_Analsysis/blob/main/Bitcoin_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. BITCOIN PRICE ANALYSIS"
      ],
      "metadata": {
        "id": "4l6ndEqiaXC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1h = get_all_bitmex(\"XBTUSD\",\"1h\",save = True)"
      ],
      "metadata": {
        "id": "o9ukNmkqtwIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1h.reset_index(level=0, inplace=True)\n",
        "df_1h = df_1h.dropna()\n",
        "df_1h.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W04w5vv6t6H0",
        "outputId": "82307c7f-056c-4e03-ab1b-13d55e21d3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  timestamp  symbol    open    high     low   close  trades  \\\n",
              "0 2015-09-25 13:00:00+00:00  XBTUSD  239.99  239.99  237.36  237.45      10   \n",
              "1 2015-09-25 14:00:00+00:00  XBTUSD  237.45  237.05  236.08  236.08       6   \n",
              "2 2015-09-25 15:00:00+00:00  XBTUSD  236.08  236.52  236.10  236.34      13   \n",
              "3 2015-09-25 16:00:00+00:00  XBTUSD  236.34  236.13  235.44  235.71      15   \n",
              "4 2015-09-25 17:00:00+00:00  XBTUSD  235.71  236.01  235.46  235.75      22   \n",
              "\n",
              "   volume     vwap  lastSize    turnover  homeNotional  foreignNotional  \n",
              "0   11501  237.418     500.0  2730544990     27.305450      6482.806927  \n",
              "1   22625  236.242    7500.0  5344986250     53.449863     12627.134051  \n",
              "2   17434  236.265     500.0  4119046040     41.190460      9731.870764  \n",
              "3   26900  235.732    1500.0  6341186000     63.411860     14948.208390  \n",
              "4   29200  235.793    1500.0  6885159000     68.851590     16234.735419  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2f91f42-e5b7-4347-8b04-bf114e660de2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>trades</th>\n",
              "      <th>volume</th>\n",
              "      <th>vwap</th>\n",
              "      <th>lastSize</th>\n",
              "      <th>turnover</th>\n",
              "      <th>homeNotional</th>\n",
              "      <th>foreignNotional</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-09-25 13:00:00+00:00</td>\n",
              "      <td>XBTUSD</td>\n",
              "      <td>239.99</td>\n",
              "      <td>239.99</td>\n",
              "      <td>237.36</td>\n",
              "      <td>237.45</td>\n",
              "      <td>10</td>\n",
              "      <td>11501</td>\n",
              "      <td>237.418</td>\n",
              "      <td>500.0</td>\n",
              "      <td>2730544990</td>\n",
              "      <td>27.305450</td>\n",
              "      <td>6482.806927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-09-25 14:00:00+00:00</td>\n",
              "      <td>XBTUSD</td>\n",
              "      <td>237.45</td>\n",
              "      <td>237.05</td>\n",
              "      <td>236.08</td>\n",
              "      <td>236.08</td>\n",
              "      <td>6</td>\n",
              "      <td>22625</td>\n",
              "      <td>236.242</td>\n",
              "      <td>7500.0</td>\n",
              "      <td>5344986250</td>\n",
              "      <td>53.449863</td>\n",
              "      <td>12627.134051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-09-25 15:00:00+00:00</td>\n",
              "      <td>XBTUSD</td>\n",
              "      <td>236.08</td>\n",
              "      <td>236.52</td>\n",
              "      <td>236.10</td>\n",
              "      <td>236.34</td>\n",
              "      <td>13</td>\n",
              "      <td>17434</td>\n",
              "      <td>236.265</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4119046040</td>\n",
              "      <td>41.190460</td>\n",
              "      <td>9731.870764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-09-25 16:00:00+00:00</td>\n",
              "      <td>XBTUSD</td>\n",
              "      <td>236.34</td>\n",
              "      <td>236.13</td>\n",
              "      <td>235.44</td>\n",
              "      <td>235.71</td>\n",
              "      <td>15</td>\n",
              "      <td>26900</td>\n",
              "      <td>235.732</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>6341186000</td>\n",
              "      <td>63.411860</td>\n",
              "      <td>14948.208390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-09-25 17:00:00+00:00</td>\n",
              "      <td>XBTUSD</td>\n",
              "      <td>235.71</td>\n",
              "      <td>236.01</td>\n",
              "      <td>235.46</td>\n",
              "      <td>235.75</td>\n",
              "      <td>22</td>\n",
              "      <td>29200</td>\n",
              "      <td>235.793</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>6885159000</td>\n",
              "      <td>68.851590</td>\n",
              "      <td>16234.735419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2f91f42-e5b7-4347-8b04-bf114e660de2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2f91f42-e5b7-4347-8b04-bf114e660de2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2f91f42-e5b7-4347-8b04-bf114e660de2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the start date and End date of the dataset\n",
        "\n",
        "sd=df_1h.iloc[0][0]\n",
        "ed=df_1h.iloc[-1][0]\n",
        "\n",
        "\n",
        "print('Starting Date',sd)\n",
        "print('Ending Date',ed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRL3jXYDt7GZ",
        "outputId": "d4b815ed-2f14-47ae-85c7-207a654414b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Date 2015-09-25 13:00:00+00:00\n",
            "Ending Date 2023-06-01 15:00:00+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total number of days present in the dataset: ',df_1h.shape[0])\n",
        "print('Total number of fields present in the dataset: ',df_1h.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z45wudAst-1N",
        "outputId": "e1d93d95-40d9-4c76-af8b-b88df76b5519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of days present in the dataset:  67097\n",
            "Total number of fields present in the dataset:  13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_1h.set_index(\"timestamp\").close.plot(figsize=(24,7), title=\"Bitcoin Closing Prices (2015-23)\",color='green')"
      ],
      "metadata": {
        "id": "u3ze14KFu9W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1h['date'] = pd.to_datetime(df_1h['timestamp'],unit='s').dt.date"
      ],
      "metadata": {
        "id": "So4jUWS5a2VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create a trace for closing prices\n",
        "trace_close = go.Scatter(\n",
        "    x=df.index,\n",
        "    y=df['close'],\n",
        "    mode='lines',\n",
        "    name='Closing Prices',\n",
        "    line=dict(color='yellow')\n",
        ")\n",
        "\n",
        "trace_ma_days = go.Scatter(\n",
        "    x=df.index,\n",
        "    y=df['close'].rolling(window=1000).mean(),\n",
        "    mode='lines',\n",
        "    name='1000 Days Moving Average',\n",
        "    line=dict(color='green')\n",
        ")\n",
        "\n",
        "# Create the layout\n",
        "layout = go.Layout(\n",
        "    title='Bitcoin Closing Prices (2015-2023)',\n",
        "    xaxis=dict(title='Date'),\n",
        "    yaxis=dict(title='Price'),\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=[trace_close, trace_ma_days], layout=layout)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "_ykwhbYbR39P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a trace for the 24-hour moving average\n",
        "trace_ma_24hr = go.Scatter(\n",
        "    x=df.index,\n",
        "    y=df['close'].rolling(window=24).mean(),\n",
        "    mode='lines',\n",
        "    name='24-hour Moving Average',\n",
        "    line=dict(color='green')\n",
        ")\n",
        "\n",
        "# Create a trace for the 48-hour moving average\n",
        "trace_ma_48hr = go.Scatter(\n",
        "    x=df.index,\n",
        "    y=df['close'].rolling(window=48).mean(),\n",
        "    mode='lines',\n",
        "    name='48-hour Moving Average',\n",
        "    line=dict(color='blue')\n",
        ")\n",
        "\n",
        "# Create the layout with a larger plot size\n",
        "layout = go.Layout(\n",
        "    title='Bitcoin Closing Prices (2015-2023)',\n",
        "    xaxis=dict(title='Date'),\n",
        "    yaxis=dict(title='Price'),\n",
        "    showlegend=True,\n",
        "    width=2000,  # Set the width of the plot in pixels\n",
        "    height=800  # Set the height of the plot in pixels\n",
        ")\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=[trace_ma_24hr, trace_ma_48hr], layout=layout)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "4sXBFzNL7tkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a figure with 3 subplots arranged in a 3x1 grid\n",
        "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 8))\n",
        "\n",
        "# plot the first dataframe on the first subplot\n",
        "mean1 = df_15_17['close'].mean()\n",
        "df_15_17['close'].hist(ax=axes[0], bins=10, alpha=0.5, color='red')\n",
        "axes[0].axvline(mean1, color='black', linestyle='dashed', linewidth=2)\n",
        "axes[0].set_title('Bitcoin Closing Price Histogram (2015-18)')\n",
        "\n",
        "# plot the second dataframe on the second subplot\n",
        "mean2 = df_18_20['close'].mean()\n",
        "df_18_20['close'].hist(ax=axes[1], bins=10, alpha=0.5, color='blue')\n",
        "axes[1].axvline(mean2, color='black', linestyle='dashed', linewidth=2)\n",
        "axes[1].set_title('Bitcoin Closing Price Histogram (2018-20)')\n",
        "\n",
        "# plot the third dataframe on the third subplot\n",
        "mean3 = df_21_23['close'].mean()\n",
        "df_21_23['close'].hist(ax=axes[2], bins=10, alpha=0.5, color='green')\n",
        "axes[2].axvline(mean3, color='black', linestyle='dashed', linewidth=2)\n",
        "axes[2].set_title('Bitcoin Closing Price Histogram (2021-23)')\n",
        "# adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pi9EsvsECRe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lag plots"
      ],
      "metadata": {
        "id": "vpk9xVSVvGrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "plt.suptitle('Lag Plots for Bitcoin Closing Price', fontsize=22)\n",
        "\n",
        "# 1-Minute Lag\n",
        "plt.subplot(3, 2, 1)\n",
        "lag_plot = pd.plotting.lag_plot(df_1h['close'], lag=1, c='orange', alpha=0.7, marker='o')\n",
        "lag_plot.axes.scatter(lag_plot.get_xlim(), lag_plot.get_ylim(), marker='o', s=3, c='orange')\n",
        "plt.title('Minute Lag')\n",
        "\n",
        "# 1-Hour Lag\n",
        "plt.subplot(3, 2, 2)\n",
        "lag_plot = pd.plotting.lag_plot(df_1h['close'], lag=60, c='orange', alpha=0.7, marker='o')\n",
        "lag_plot.axes.scatter(lag_plot.get_xlim(), lag_plot.get_ylim(), marker='o', s=3, c='orange')\n",
        "plt.title('Hourly Lag')\n",
        "\n",
        "# Daily Lag\n",
        "plt.subplot(3, 2, 3)\n",
        "lag_plot = pd.plotting.lag_plot(df_1h['close'], lag=1440, c='orange', alpha=0.7, marker='o')\n",
        "lag_plot.axes.scatter(lag_plot.get_xlim(), lag_plot.get_ylim(), marker='o', s=3, c='orange')\n",
        "plt.title('Daily Lag')\n",
        "\n",
        "# Weekly Lag\n",
        "plt.subplot(3, 2, 4)\n",
        "lag_plot = pd.plotting.lag_plot(df_1h['close'], lag=10080, c='orange', alpha=0.7, marker='o')\n",
        "lag_plot.axes.scatter(lag_plot.get_xlim(), lag_plot.get_ylim(), marker='o', s=3, c='orange')\n",
        "plt.title('Weekly Lag')\n",
        "\n",
        "# 1-Month Lag\n",
        "plt.subplot(3, 2, 5)\n",
        "lag_plot = pd.plotting.lag_plot(df_1h['close'], lag=43200, c='orange', alpha=0.7, marker='o')\n",
        "lag_plot.axes.scatter(lag_plot.get_xlim(), lag_plot.get_ylim(), marker='o', s=3, c='orange')\n",
        "plt.title('Monthly Lag')\n",
        "\n",
        "plt.tight_layout()  # Improves subplot spacing\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0i09SkRQfuDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stationarity check and STL-decomposition of the series"
      ],
      "metadata": {
        "id": "V9KOnn4dPk2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resampling to daily,monthy frequency\n",
        "df_1h.index = df_1h.timestamp\n",
        "df_day = df_1h.resample('D').mean()\n",
        "df_month = df_1h.resample('M').mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR_9fcadpXhS",
        "outputId": "80447311-3202-416d-96bb-4e72ffba2f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-78947312a8c4>:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_day = df_1h.resample('D').mean()\n",
            "<ipython-input-21-78947312a8c4>:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_month = df_1h.resample('M').mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADF Test on hourly data\n",
        "# Function to print out results in customised manner\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "def adf_test(timeseries):\n",
        "    print ('Results of Dickey-Fuller Test:')\n",
        "    dftest = adfuller(timeseries, autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput['Critical Value (%s)'%key] = value\n",
        "    print (dfoutput)\n",
        "# Call the function and run the test\n",
        "\n",
        "adf_test(df_1h['close'])"
      ],
      "metadata": {
        "id": "qjzLtU25v9vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since p-value > 0.05, we fail to reject the null hypothesis. Hence the series is non-stationary."
      ],
      "metadata": {
        "id": "aU75hSspuRmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[30,10])\n",
        "sm.tsa.seasonal_decompose(df_month.close).plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b3d5ku9MP8YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In the above plots clearly trend and seasonality can be obeserved."
      ],
      "metadata": {
        "id": "kRcDLfAbseMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_day['Weighted_Price_box'], lmbda = stats.boxcox(df_day.close)\n",
        "print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(df_day.close)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Mjz_sosdjN",
        "outputId": "bddbed43-3109-492f-975a-5aa72d690e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dickey–Fuller test: p=0.431530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**KPSS TEST**"
      ],
      "metadata": {
        "id": "VNuCoy4ea0fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import kpss\n",
        "def kpss_test(timeseries):\n",
        "    print ('Results of KPSS Test:')\n",
        "    kpsstest = kpss(timeseries, regression='c', nlags=\"auto\")\n",
        "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','#Lags Used'])\n",
        "    for key,value in kpsstest[3].items():\n",
        "        kpss_output['Critical Value (%s)'%key] = value\n",
        "    print (kpss_output)"
      ],
      "metadata": {
        "id": "jJWryNRzT5AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kpss_test(df_day['close'])"
      ],
      "metadata": {
        "id": "rpSi_-0wT5Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting Non-Stationary Into Stationary (applying 3 different methods till stationarity is obtained)"
      ],
      "metadata": {
        "id": "E1zhFBOhgA6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Box-Cox Transformations** - Formally, A Box cox transformation is defined as a way to transform non-normal dependent variables in our data to a normal shape through which we can run a lot more tests than we could have."
      ],
      "metadata": {
        "id": "btRz5Pnl08pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_month['Weighted_Price_box'], lmbda = stats.boxcox(df_month.close)\n",
        "print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(df_month.close)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMgPBDntlSTi",
        "outputId": "57d104e8-684d-441f-8e3b-b66bf0f3e23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dickey–Fuller test: p=0.492575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Seasonal differentiation**\n"
      ],
      "metadata": {
        "id": "Z4XSjIK9j8b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_month['prices_box_diff'] = df_month.Weighted_Price_box - df_month.Weighted_Price_box.shift(12)\n",
        "print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(df_month.prices_box_diff[12:])[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSxgTIjykFb8",
        "outputId": "30a1eccd-8bec-4e11-84be-c1d3344dbad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dickey–Fuller test: p=0.093748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regular differentiation**"
      ],
      "metadata": {
        "id": "SiT65faOkqfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_month['prices_box_diff2'] = df_month.prices_box_diff - df_month.prices_box_diff.shift(1)\n",
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "# STL-decomposition\n",
        "sm.tsa.seasonal_decompose(df_month.prices_box_diff2[13:]).plot()\n",
        "print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(df_month.prices_box_diff2[13:])[1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hk-FXRJikTIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autocorrelation and Partial Autocorrelation Plots for Model Selection -"
      ],
      "metadata": {
        "id": "V6sSZL-toui-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial approximation of parameters using Autocorrelation and Partial Autocorrelation Plots\n",
        "plt.figure(figsize=(15,7))\n",
        "ax = plt.subplot(211)\n",
        "sm.graphics.tsa.plot_acf(df_month.prices_box_diff2[13:].values.squeeze(), lags=30, ax=ax)\n",
        "ax = plt.subplot(212)\n",
        "sm.graphics.tsa.plot_pacf(df_month.prices_box_diff2[13:].values.squeeze(), lags=30, ax=ax)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bpn1x9ZIo9TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SARIMA**"
      ],
      "metadata": {
        "id": "IJUCULKFqB4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LYtndGDANoO"
      },
      "outputs": [],
      "source": [
        "# First order diferencing for the close price to remove the trend and seasonality\n",
        "daily_return = data[\"close\"].pct_change(1).dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xdPDZ8xANoT"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(daily_return) * 0.8)\n",
        "train_data = daily_return[:train_size]\n",
        "test_data  = daily_return[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8xvP3zENANoU"
      },
      "outputs": [],
      "source": [
        "pip install pmdarima\n",
        "from pmdarima.arima import auto_arima\n",
        "\n",
        "model = auto_arima(train_data, trace=True, error_action='ignore', suppress_warnings=True)\n",
        "model.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLQ54gerqLtf"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import SARIMA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "import random\n",
        "\n",
        "# Define the p, d, and q parameters for the ARIMA model\n",
        "p = 0\n",
        "d = 0\n",
        "q = 5\n",
        "\n",
        "# Create the ARIMA model\n",
        "model = SARIMA(train_data, order=(p, d, q))\n",
        "\n",
        "# Fit the model\n",
        "res = model.fit()\n",
        "\n",
        "# Get the predicted values\n",
        "pred_train = res.predict()\n",
        "predicted_returns = res.predict(start=test_data.index[0], end=test_data.index[-1])\n",
        "\n",
        "# Compute the actual returns\n",
        "actual_train = train_data\n",
        "actual_returns = test_data\n",
        "\n",
        "# Calculate the RMSE and MAE for the predicted and actual returns\n",
        "rmse_train = mean_squared_error(actual_train, pred_train) ** 0.5\n",
        "mae_train = mean_absolute_error(actual_train, pred_train)\n",
        "\n",
        "# Calculate the RMSE and MAE for the predicted and actual returns\n",
        "rmse_pred = mean_squared_error(actual_returns, predicted_returns) ** 0.5\n",
        "mae_pred = mean_absolute_error(actual_returns, predicted_returns)\n",
        "\n",
        "print('ARIMA({},{},{}) model summary:\\n{}'.format(p, d, q, res.summary()))\n",
        "print('RMSE for train data:', rmse_train)\n",
        "print('MAE for train data:', mae_train)\n",
        "\n",
        "print('RMSE for test data:', rmse_pred)\n",
        "print('MAE for test_data:', mae_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM**"
      ],
      "metadata": {
        "id": "ZklokWUB3Ly7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1h.drop(['timestamp','symbol','trades','lastSize','turnover','homeNotional','foreignNotional'],inplace=True,axis=1)\n",
        "#print(bitcoin_market_info.head())\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df_1h)"
      ],
      "metadata": {
        "id": "fp6TGSRk0ixi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=df_1h.columns\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tnames += [(j) for j in columns]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [(\"output \"+j) for j in columns]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "metadata": {
        "id": "kBDbDCRi0i79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reframed = series_to_supervised(scaled, 1, 1)\n",
        "ref=series_to_supervised(df_1h.values,1,1)\n",
        "ref.drop(ref.columns[[7,8,9,10,11]], axis=1, inplace=True)\n",
        "print(ref.head())"
      ],
      "metadata": {
        "id": "2JlKylZg3jsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reframed.shape)\n",
        "print(df_1h.shape)"
      ],
      "metadata": {
        "id": "Ex6KaFUc3qGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef822d7-c584-412f-ec77-fb438d5f4b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(67098, 14)\n",
            "(67099, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reframed.drop(reframed.columns[[7,8,9,10,11]], axis=1, inplace=True)\n",
        "print(reframed.head())"
      ],
      "metadata": {
        "id": "xiibriBS3tnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values=reframed.values\n",
        "test = values[9:1500, :]\n",
        "train = values[1500:, :]\n",
        "# split into input and outputs\n",
        "train_X, train_y = train[:, :-1], train[:, -1]\n",
        "test_X, test_y = test[:, :-1], test[:, -1]\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "metadata": {
        "id": "zsJeu9CH3wpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(80, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "history = model.fit(train_X, train_y, epochs=12, batch_size=, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
      ],
      "metadata": {
        "id": "h6TZUc4p31jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot history\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "#plt.plot(history.history['val_loss'], label='test_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D-mv00OhFLGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "yhat = model.predict(test_X)\n",
        "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "# invert scaling for forecast\n",
        "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "# invert scaling for actual\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "# calculate RMSE\n",
        "rmse =np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "metadata": {
        "id": "p4wyFRd0JERI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_19_23 = df_1h[28399:]"
      ],
      "metadata": {
        "id": "hAbCmWv1Le6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = df_19_23[['close']].values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(dataset)\n",
        "\n",
        "# create training and testing data\n",
        "train_size = int(len(scaled_data) * 0.7)\n",
        "test_size = len(scaled_data) - train_size\n",
        "train_data, test_data = scaled_data[0:train_size,:], scaled_data[train_size:len(scaled_data),:]\n",
        "\n",
        "# create function to create dataset with look back\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# reshape data\n",
        "look_back = 5\n",
        "trainX, trainY = create_dataset(train_data, look_back)\n",
        "testX, testY = create_dataset(test_data, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# define optimizer\n",
        "optimizer = Adam(lr=0.001, clipvalue=1.0)\n",
        "#optimizer='adam'\n",
        "\n",
        "# define and train model LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1, look_back)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "# define callbacks\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss')\n",
        "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "# train model\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=32, verbose=2, callbacks=[es], validation_split=0.2)\n",
        "#model.fit(trainX, trainY, epochs=100, batch_size=256, verbose=2)\n",
        "\n",
        "# make predictions\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform([trainY])\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform([testY])\n",
        "\n",
        "# calculate root mean squared error\n",
        "trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n"
      ],
      "metadata": {
        "id": "A-P8F8PFliCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_p = testPredict.reshape(-1, 1)\n",
        "\n",
        "test_y = testY.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "CPNCaJH8TWwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "\n",
        "# Plot a subset of the data\n",
        "plt.plot(test_p[:1000], 'r', marker='.', label='Predicted Test')\n",
        "plt.plot(test_y[:1000], marker='.', label='Actual Test')\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hjhaL7RqPanx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**XGBOOST**"
      ],
      "metadata": {
        "id": "WL9vnlRw7WqY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGceVYPjijLg"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(len(data) * 0.8)\n",
        "train_data = data[:train_size]\n",
        "test_data  = data[train_size:]\n",
        "\n",
        "y_train = train_data['close']\n",
        "y_test = test_data['close']\n",
        "\n",
        "# Scale the input data\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train_data)\n",
        "test_scaled = scaler.transform(test_data)\n",
        "\n",
        "# Create the DMatrix from the scaled training data\n",
        "dtrain = xgb.DMatrix(train_scaled, label=y_train)\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb.XGBRegressor(objective='reg:squarederror', seed=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    verbose=1\n",
        ")\n",
        "grid_search.fit(train_scaled, y_train)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Perform random search\n",
        "param_dist = {\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    'n_estimators': [100, 200, 300, 400, 500]\n",
        "}\n",
        "\n",
        "# Perform random search\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb.XGBRegressor(objective='reg:squarederror', seed=42),\n",
        "    param_distributions=param_dist,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    n_iter=10,  # Number of random combinations to try\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "random_search.fit(train_scaled, y_train)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred = best_model.predict(test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Plot actual vs predicted\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=test_data.index, y=y_test, mode='lines', name='Actual'))\n",
        "fig.add_trace(go.Scatter(x=test_data.index, y=y_pred, mode='markers', name='Predicted',marker=dict(size=1)))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Actual vs Predicted',\n",
        "    xaxis_title='Sample',\n",
        "    yaxis_title='Value'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "FCLWrE2zDSCC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}